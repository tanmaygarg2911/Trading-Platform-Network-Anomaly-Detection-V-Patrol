{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_After obtaining `output2`, I separated the Boolean columns, `normalized_distance`, and `similarity_score` from the rest of the dataset. I then ran the model on both datasets and achieved better results with the dataset containing the specified columns._**\n",
    "\n",
    "#### Output 3\n",
    "**Best parameters:** `{'n_estimators': 150, 'max_samples': 128, 'contamination': 0.1602582555413908, 'max_features': 0.9, 'bootstrap': False}`\n",
    "**Best score:** `0.719502379676749`\n",
    "\n",
    "\n",
    "In the third iteration, I introduced a new value for `contamination` and increased `n_estimators` to `150`. This resulted in a significant improvement, with the best score reaching `0.719502379676749`.\n",
    "\n",
    "#### Output 4\n",
    "**Best parameters:** `{'n_estimators': 150, 'max_samples': 64, 'contamination': 0.1, 'max_features': 0.9, 'bootstrap': False}`\n",
    "**Best score:** `0.7301869661156942`\n",
    "\n",
    "In the fourth iteration, I further reduced `max_samples` to `64`, which led to an even better score of `0.7301869661156942`. This iteration confirmed that a smaller sample size was beneficial for the model's performance.\n",
    "\n",
    "In the final iteration, I confirmed the best parameters from the previous iteration. The score remained consistent at `0.7301869661156942`, indicating that the model had reached an optimal configuration for the given dataset.\n",
    "\n",
    "### Conclusion\n",
    "Through each iteration, I systematically explored different hyperparameter combinations and derived insights from previous results. This iterative approach allowed me to progressively improve the model's performance, ultimately achieving a significant increase in the best score from `0.6556688332880479` to `0.7301869661156942`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (replace with your dataset)\n",
    "data = pd.read_csv(r\"C:\\Users\\Tanmay\\V-Patrol\\work\\final.csv\")\n",
    "data.drop(columns=[\"Unnamed: 0\",\"Unnamed: 0.1\",\"Unnamed: 0.2\",\"Unnamed: 0.3\",\"Unnamed: 0.4\",\"Unnamed: 0.5\",\"Unnamed: 0.6\",\"Unnamed: 0.7\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean columns to int64\n",
    "bool_columns = data.select_dtypes(include='bool').columns\n",
    "data[bool_columns] = data[bool_columns].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the parameter grid with sampled values\n",
    "param_grid = {\n",
    "    'n_estimators': [100,150],\n",
    "    'max_samples': [32,64, 128],\n",
    "    'contamination': [0.1],\n",
    "    'max_features': [0.75, 0.90,1],\n",
    "    'bootstrap': [False]\n",
    "}\n",
    "\n",
    "\n",
    "def hybrid_scorer(scores):\n",
    "    norm_scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "    cluster_labels = KMeans(n_clusters=2, n_init=10).fit_predict(norm_scores.reshape(-1, 1))\n",
    "    cluster_score = silhouette_score(norm_scores.reshape(-1, 1), cluster_labels)\n",
    "\n",
    "    return cluster_score\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "# Nested for loops to iterate over parameter combinations\n",
    "for n_estimators in param_grid['n_estimators']:\n",
    "    for max_samples in param_grid['max_samples']:\n",
    "        for contamination in param_grid['contamination']:\n",
    "            for max_features in param_grid['max_features']:\n",
    "                for bootstrap in param_grid['bootstrap']:\n",
    "                    # Initialize the model with the current parameters\n",
    "                    model = IsolationForest(\n",
    "                        n_estimators=n_estimators,\n",
    "                        max_samples=max_samples,\n",
    "                        contamination=contamination,\n",
    "                        max_features=max_features,\n",
    "                        bootstrap=bootstrap,\n",
    "                        random_state=42\n",
    "                    )\n",
    "\n",
    "                    # Perform cross-validation\n",
    "                    fold_scores = []\n",
    "                    for train_index, test_index in kf.split(X):\n",
    "                        X_train, X_test = X[train_index], X[test_index]\n",
    "                        model.fit(X_train)\n",
    "                        scores = model.decision_function(X_test)\n",
    "                        score = hybrid_scorer(scores)\n",
    "                        fold_scores.append(score)\n",
    "\n",
    "                    # Calculate mean score for the current parameter combination\n",
    "                    mean_score = np.mean(fold_scores)\n",
    "                    results.append({\n",
    "                        'params': {\n",
    "                            'n_estimators': n_estimators,\n",
    "                            'max_samples': max_samples,\n",
    "                            'contamination': contamination,\n",
    "                            'max_features': max_features,\n",
    "                            'bootstrap': bootstrap\n",
    "                        },\n",
    "                        'mean_score': mean_score\n",
    "                    })\n",
    "\n",
    "                    print(f\"Parameters: {n_estimators}, {max_samples}, {contamination}, {max_features}, {bootstrap}\")\n",
    "                    print(f\"Mean Score: {mean_score}\")\n",
    "\n",
    "                    if mean_score == np.nan:\n",
    "                        print(\"Mean score is NaN. Skipping this iteration.\")\n",
    "                        sys.exit()\n",
    "\n",
    "                    # Update best score and parameters if current mean score is better\n",
    "                    if mean_score > best_score:\n",
    "                        best_score = mean_score\n",
    "                        best_params = {\n",
    "                            'n_estimators': n_estimators,\n",
    "                            'max_samples': max_samples,\n",
    "                            'contamination': contamination,\n",
    "                            'max_features': max_features,\n",
    "                            'bootstrap': bootstrap\n",
    "                        }\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "\n",
    "# Print all results\n",
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
